## ğŸ•¸ï¸ Parallel Web Crawler

A multi-threaded web crawler built in Java that parses and analyzes web pages to extract popular words and measure performance.
This project is an enhancement of a legacy single-threaded crawler, upgraded to leverage parallelism with ForkJoinPool for faster throughput.

# ğŸš€ Features

Parallel crawling using ForkJoinPool.

Configurable JSON settings (start pages, max depth, timeout, ignored words/URLs, parallelism level, etc.).

Result output in JSON including:

Word frequency count (top N popular words).

Number of unique URLs visited.

Performance profiling with execution time for annotated methods.

Functional word counting using Java Streams (no loops).

# âš™ï¸ Tech Stack

Java 17

Maven (build tool)

Jackson (JSON parsing & writing)

Jsoup (HTML parsing)

JUnit 5 & Truth (unit testing)

Guice (dependency injection)

# ğŸ“‚ Project Structure
src/
 â”œâ”€â”€ main/java/com/udacity/webcrawler/
 â”‚    â”œâ”€â”€ json/                # JSON config & result handling
 â”‚    â”œâ”€â”€ parser/              # Page parsing logic
 â”‚    â”œâ”€â”€ profiler/            # Method profiling utilities
 â”‚    â”œâ”€â”€ main/                # Entry point (WebCrawlerMain.java)
 â”‚    â”œâ”€â”€ SequentialWebCrawler # Legacy single-threaded crawler
 â”‚    â””â”€â”€ ParallelWebCrawler   # New parallel crawler
 â””â”€â”€ test/java/com/udacity/webcrawler/
      â””â”€â”€ ... (JUnit tests)

# ğŸ› ï¸ Setup & Run
Prerequisites

Java JDK 17+

Maven 3.6.3+

Build
mvn clean package

Run (Legacy Sequential Crawler)
java -classpath target/udacity-webcrawler-1.0.jar \
    com.udacity.webcrawler.main.WebCrawlerMain \
    src/main/config/sample_config_sequential.json

Run (Parallel Crawler)
java -classpath target/udacity-webcrawler-1.0.jar \
    com.udacity.webcrawler.main.WebCrawlerMain \
    src/main/config/sample_config.json

# ğŸ§ª Running Tests
# Run all tests
mvn test

# Run specific test
mvn test -Dtest=WebCrawlerTest

# ğŸ“Š Example Output

Crawl Result (crawlResults.json)

{
  "wordCounts": {
    "crawler": 12,
    "java": 8,
    "parallel": 5
  },
  "urlsVisited": 15
}


Profiler Output (profileData.txt)

Run at Tue, 02 Sep 2025 18:45:21 GMT
com.udacity.webcrawler.ParallelWebCrawler#crawl took 0m 1s 412ms
com.udacity.webcrawler.parser.PageParserImpl#parse took 0m 2s 38ms

#ğŸ“Œ Learning Outcomes

Implemented builder pattern with Jackson for config handling.

Used ForkJoinPool for recursive parallelism.

Designed thread-safe data structures for concurrent crawling.

Applied functional programming (Java Streams) for word counting.

Built a custom profiler using dynamic proxies & annotations.

#ğŸ“„ License

This project is open-source under the MIT License.

âœ¨ Built with Java, concurrency, and a love for clean code.